{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import collections\n",
    "import gzip\n",
    "import io\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm \n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.io import mmread\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import umap.umap_ as umap\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_VCF_gz(path):\n",
    "\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        \n",
    "        lines = [l.decode('utf-8') for l in f if not l.startswith(b'##')]\n",
    "\n",
    "    return pd.read_csv(\n",
    "        io.StringIO(''.join(lines)),\n",
    "        dtype={'#CHROM': str, 'POS': int, 'ID': str, 'REF': str, 'ALT': str,\n",
    "               'QUAL': str, 'FILTER': str, 'INFO': str},\n",
    "        sep='\\t'\n",
    "    ).rename(columns={'#CHROM': 'CHROM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2156de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n):\n",
    "\n",
    "    ret = np.cumsum(a)\n",
    "    ret[n: ] = ret[n: ] - ret[ : -n]\n",
    "\n",
    "    return ret[n-1: ] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_normalized(nn.Module):\n",
    "    \n",
    "    def __init__(self, obs_dim, z_dim):\n",
    "\n",
    "        super(VAE_normalized, self).__init__()\n",
    "        self.fc1 = nn.Linear(obs_dim, z_dim, bias = False)\n",
    "        self.fc2 = nn.Linear(obs_dim, z_dim, bias = False)\n",
    "        self.fc3 = nn.Linear(z_dim, obs_dim)\n",
    "\n",
    "    def encode(self, x, cell_SNPread_weight):\n",
    "\n",
    "        return self.fc1(torch.logit(x, eps = 0.01)) / cell_SNPread_weight * torch.mean(cell_SNPread_weight), self.fc2(torch.logit(x, eps = 0.01)) / cell_SNPread_weight * torch.mean(cell_SNPread_weight)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "\n",
    "        return torch.sigmoid(self.fc3(z))\n",
    "\n",
    "    def forward(self, x, cell_SNPread_weight):\n",
    "\n",
    "        mu, log_var = self.encode(x, cell_SNPread_weight) \n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst_mu = self.decode(z)\n",
    "\n",
    "        return x_reconst_mu, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_unnormalized(nn.Module):\n",
    "    \n",
    "    def __init__(self, obs_dim, z_dim):\n",
    "\n",
    "        super(VAE_unnormalized, self).__init__()\n",
    "        self.fc1 = nn.Linear(obs_dim, z_dim, bias = False)\n",
    "        self.fc2 = nn.Linear(obs_dim, z_dim, bias = False)\n",
    "        self.fc3 = nn.Linear(z_dim, obs_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "\n",
    "        return self.fc1(torch.logit(x, eps = 0.01)), self.fc2(torch.logit(x, eps = 0.01))\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "\n",
    "        return torch.sigmoid(self.fc3(z))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        mu, log_var = self.encode(x) \n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst_mu = self.decode(z)\n",
    "\n",
    "        return x_reconst_mu, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a5e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(self, path, mitoSNP_mask, AD, DP, VCF, variant_name):\n",
    "    \n",
    "    print(\"Start loading raw data.\")\n",
    "    \n",
    "    if path != None:\n",
    "    \n",
    "        VCF_raw = read_VCF_gz(path + \"/cellSNP.base.vcf.gz\")\n",
    "        is_VCF = True\n",
    "        \n",
    "    elif path == None and VCF != None:\n",
    "        \n",
    "        VCF_raw = read_VCF_gz(VCF)\n",
    "        is_VCF = True\n",
    "        \n",
    "    elif path == None and VCF == None:\n",
    "        \n",
    "        VCF_raw = pd.read_csv(variant_name, delimiter = \"\\t\", header = None)\n",
    "        is_VCF = False\n",
    "        \n",
    "    if is_VCF == True:\n",
    "    \n",
    "        mitoSNP_filter = np.ones(VCF_raw.shape[0])\n",
    "    \n",
    "        for j in range(VCF_raw.shape[0]):\n",
    "\n",
    "            if VCF_raw[\"CHROM\"][j] == 'chrM' and VCF_raw[\"POS\"][j] in mitoSNP_mask:\n",
    "\n",
    "                mitoSNP_filter[j] = 0\n",
    "\n",
    "            if VCF_raw[\"CHROM\"][j] == 'chrMT' and VCF_raw[\"POS\"][j] in mitoSNP_mask:\n",
    "\n",
    "                mitoSNP_filter[j] = 0\n",
    "\n",
    "            if VCF_raw[\"CHROM\"][j] == 'M' and VCF_raw[\"POS\"][j] in mitoSNP_mask:\n",
    "\n",
    "                mitoSNP_filter[j] = 0\n",
    "\n",
    "            if VCF_raw[\"CHROM\"][j] == 'MT' and VCF_raw[\"POS\"][j] in mitoSNP_mask:\n",
    "\n",
    "                mitoSNP_filter[j] = 0\n",
    "\n",
    "        mitoSNP_filter = mitoSNP_filter.astype(bool)\n",
    "\n",
    "        VCF_raw = VCF_raw[mitoSNP_filter]\n",
    "    \n",
    "    if path != None:\n",
    "        \n",
    "        AD_raw = mmread(path + '/cellSNP.tag.AD.mtx').toarray()[mitoSNP_filter, :].T\n",
    "        DP_raw = mmread(path + '/cellSNP.tag.DP.mtx').toarray()[mitoSNP_filter, :].T\n",
    "        \n",
    "    elif path == None:\n",
    "        \n",
    "        if is_VCF == True:\n",
    "        \n",
    "            AD_raw = mmread(AD).toarray()[mitoSNP_filter, :].T\n",
    "            DP_raw = mmread(DP).toarray()[mitoSNP_filter, :].T\n",
    "            \n",
    "        elif is_VCF == False:\n",
    "            \n",
    "            AD_raw = mmread(AD).toarray().T\n",
    "            DP_raw = mmread(DP).toarray().T\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        \n",
    "        warnings.filterwarnings(\"ignore\", category = RuntimeWarning)\n",
    "        AF_raw_missing_to_mean = AD_raw / DP_raw\n",
    "        \n",
    "    AF_mean = np.nanmean(AF_raw_missing_to_mean, 0)\n",
    "    AF_raw_missing_to_mean[np.isnan(AF_raw_missing_to_mean)] = np.outer(np.ones(AF_raw_missing_to_mean.shape[0]), AF_mean)[np.isnan(AF_raw_missing_to_mean)]\n",
    "    AF_raw_missing_to_mean = torch.tensor(AF_raw_missing_to_mean).float()\n",
    "    \n",
    "    self.path = path\n",
    "    self.VCF_raw = VCF_raw\n",
    "    self.mitoSNP_mask = mitoSNP_mask\n",
    "    self.is_VCF = is_VCF\n",
    "    \n",
    "    if is_VCF == True:\n",
    "        \n",
    "        self.mitoSNP_filter = mitoSNP_filter\n",
    "        \n",
    "    self.AD_raw = AD_raw\n",
    "    self.DP_raw = DP_raw\n",
    "    self.AF_mean = AF_mean\n",
    "    self.AF_raw_missing_to_mean = AF_raw_missing_to_mean\n",
    "\n",
    "    print(\"Finish loading raw data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c481151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(self):\n",
    "    \n",
    "    print(\"Start filtering low-quality cells and SNPs.\")\n",
    "    \n",
    "    cell_SNPread = np.sum(np.array(self.DP_raw) > 0, 1)\n",
    "    \n",
    "    plt.figure(figsize = (10, 7))\n",
    "    plt.title(\"Cells sorted by number of observed SNPs\")\n",
    "    plt.plot(np.arange(cell_SNPread.shape[0]) + 1, np.flip(np.sort(cell_SNPread)))\n",
    "    plt.ylabel(\"Number of observed SNPs\")\n",
    "    plt.xlabel(\"Cell\")\n",
    "    plt.show()\n",
    "    \n",
    "    cell_SNPread_threshold = float(input(\"Please determine y-axis threshold in the plot to filter low-quality cells with low number of observed SNPs.   \"))\n",
    "    cell_filter = cell_SNPread > cell_SNPread_threshold\n",
    "    cell_total = np.sum(cell_filter)\n",
    "    \n",
    "    SNP_DPmean = np.mean(self.DP_raw[cell_filter, :], 0)\n",
    "    \n",
    "    plt.figure(figsize = (10, 7))\n",
    "    plt.title(\"Mean coverage of SNPs per high-quality cell\")\n",
    "    plt.plot(np.arange(SNP_DPmean.shape[0]) + 1, SNP_DPmean)\n",
    "    plt.ylabel(\"Mean coverage\")\n",
    "    plt.xlabel(\"SNP\")\n",
    "    plt.show()\n",
    "    \n",
    "    SNP_DPmean_threshold = float(input(\"Please determine y-axis threshold in the plot to filter low-quality SNPs with low coverage.   \"))\n",
    "    SNP_DPmean_filter = SNP_DPmean > SNP_DPmean_threshold\n",
    "    \n",
    "    SNP_logit_var = torch.var(torch.logit(self.AF_raw_missing_to_mean[cell_filter, :], eps = 0.01), 0).cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize = (10, 7))\n",
    "    plt.title(\"SNPs sorted by logit-variance\")\n",
    "    plt.plot(np.arange(np.sum(SNP_DPmean_filter)) + 1, np.flip(np.sort((SNP_logit_var[SNP_DPmean_filter]))))\n",
    "    plt.ylabel(\"Logit-variance of SNP\")\n",
    "    plt.xlabel(\"SNP\")\n",
    "    plt.show()\n",
    "    \n",
    "    SNP_logit_var_threshold = float(input(\"Please determine y-axis threshold in the plot to filter low-quality SNPs with low logit-variance.   \"))\n",
    "    SNP_logit_var_filter = SNP_logit_var > SNP_logit_var_threshold\n",
    "    SNP_filter = np.logical_and(SNP_DPmean_filter, SNP_logit_var_filter)\n",
    "    cell_SNPread_filtered = np.sum(self.DP_raw[cell_filter, :][:, SNP_filter] > 0, 1)\n",
    "    \n",
    "    while (cell_SNPread_filtered == 0).any():\n",
    "        \n",
    "        SNP_logit_var_threshold = float(input(f\"{np.sum(cell_SNPread_filtered == 0)} cells have 0 observed SNPs, please determine a lower y-axis threshold.   \"))\n",
    "        SNP_logit_var_filter = SNP_logit_var > SNP_logit_var_threshold\n",
    "        SNP_filter = np.logical_and(SNP_DPmean_filter, SNP_logit_var_filter)\n",
    "        cell_SNPread_filtered = np.sum(self.DP_raw[cell_filter, :][:, SNP_filter] > 0, 1)\n",
    "    \n",
    "    SNP_total = np.sum(SNP_filter)\n",
    "    \n",
    "    AD_filtered = self.AD_raw[cell_filter, :][:, SNP_filter]\n",
    "    DP_filtered = self.DP_raw[cell_filter, :][:, SNP_filter]\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        \n",
    "        warnings.filterwarnings(\"ignore\", category = RuntimeWarning)\n",
    "        AF_filtered = AD_filtered / DP_filtered\n",
    "        \n",
    "    AF_filtered_mean = np.nanmean(AF_filtered, 0)\n",
    "    AF_filtered_missing_to_nan = np.copy(AF_filtered)\n",
    "    AF_filtered_missing_to_zero = np.copy(AF_filtered)\n",
    "    AF_filtered_missing_to_mean = np.copy(AF_filtered)\n",
    "    AF_filtered_missing_to_half = np.copy(AF_filtered)\n",
    "    \n",
    "    if self.missing_value == \"mean\":\n",
    "        \n",
    "        AF_filtered[np.isnan(AF_filtered)] = np.outer(np.ones(cell_total), AF_filtered_mean)[np.isnan(AF_filtered)]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        AF_filtered[np.isnan(AF_filtered)] = self.missing_value\n",
    "    \n",
    "    AF_filtered = torch.tensor(AF_filtered).float()\n",
    "    AF_filtered_missing_to_zero[np.isnan(AF_filtered_missing_to_zero)] = 0\n",
    "    AF_filtered_missing_to_zero = torch.tensor(AF_filtered_missing_to_zero).float()\n",
    "    AF_filtered_missing_to_mean[np.isnan(AF_filtered_missing_to_mean)] = np.outer(np.ones(cell_total), AF_filtered_mean)[np.isnan(AF_filtered_missing_to_mean)]\n",
    "    AF_filtered_missing_to_mean = torch.tensor(AF_filtered_missing_to_mean).float()\n",
    "    AF_filtered_missing_to_half[np.isnan(AF_filtered_missing_to_half)] = 0.5\n",
    "    AF_filtered_missing_to_half = torch.tensor(AF_filtered_missing_to_half).float()\n",
    "    \n",
    "    if self.is_VCF == True:\n",
    "        \n",
    "        pd.options.mode.chained_assignment = None\n",
    "        VCF_filtered = self.VCF_raw.iloc[SNP_filter, :]\n",
    "        VCF_filtered[\"TEXT\"] = \"chr:\" + VCF_filtered[\"CHROM\"].astype(str) + \", \" + VCF_filtered[\"POS\"].astype(str) + VCF_filtered[\"REF\"] + \">\" + VCF_filtered[\"ALT\"]\n",
    "        pd.options.mode.chained_assignment = 'warn'\n",
    "        \n",
    "    elif self.is_VCF == False:\n",
    "        \n",
    "        VCF_filtered = self.VCF_raw.iloc[SNP_filter, :]\n",
    "    \n",
    "    self.cell_SNPread = cell_SNPread\n",
    "    self.cell_SNPread_threshold = cell_SNPread_threshold\n",
    "    self.cell_filter = cell_filter\n",
    "    self.cell_total = cell_total\n",
    "    self.SNP_DPmean = SNP_DPmean\n",
    "    self.SNP_DPmean_threshold = SNP_DPmean_threshold\n",
    "    self.SNP_DPmean_filter = SNP_DPmean_filter\n",
    "    self.SNP_logit_var = SNP_logit_var\n",
    "    self.SNP_logit_var_threshold = SNP_logit_var_threshold\n",
    "    self.SNP_logit_var_filter = SNP_logit_var_filter\n",
    "    self.SNP_filter = SNP_filter\n",
    "    self.cell_SNPread_filtered = cell_SNPread_filtered\n",
    "    self.SNP_total = SNP_total\n",
    "    self.AD_filtered = AD_filtered\n",
    "    self.DP_filtered = DP_filtered\n",
    "    self.AF_filtered = AF_filtered\n",
    "    self.AF_filtered_mean = AF_filtered_mean\n",
    "    self.AF_filtered_missing_to_nan = AF_filtered_missing_to_nan\n",
    "    self.AF_filtered_missing_to_zero = AF_filtered_missing_to_zero\n",
    "    self.AF_filtered_missing_to_mean = AF_filtered_missing_to_mean\n",
    "    self.AF_filtered_missing_to_half = AF_filtered_missing_to_half\n",
    "    self.VCF_filtered = VCF_filtered\n",
    "    \n",
    "    print(f\"Finish filtering low-quality data, {cell_total} cells and {SNP_total} SNPs will be used for downstream analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dee98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_filtering(self, dpi):\n",
    "    \n",
    "    print(f\"Finish filtering low-quality data, {self.cell_total} cells and {self.SNP_total} SNPs will be used for downstream analysis.\")\n",
    "    \n",
    "    plt.figure(figsize = (10, 7), dpi = dpi)\n",
    "    plt.title(\"Cells sorted by number of observed SNPs\")\n",
    "    plt.plot(np.arange(self.cell_SNPread.shape[0]) + 1, np.flip(np.sort(self.cell_SNPread)))\n",
    "    plt.ylabel(\"Number of observed SNPs\")\n",
    "    plt.xlabel(\"Cell\")\n",
    "    plt.axhline(y = self.cell_SNPread_threshold, color = 'r', linestyle = '-')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize = (10, 7), dpi = dpi)\n",
    "    plt.title(\"Mean coverage of SNPs per high-quality cell\")\n",
    "    plt.plot(np.arange(self.SNP_DPmean.shape[0]) + 1, self.SNP_DPmean)\n",
    "    plt.ylabel(\"Mean coverage\")\n",
    "    plt.xlabel(\"SNP\")\n",
    "    plt.axhline(y = self.SNP_DPmean_threshold, color = 'r', linestyle = '-')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize = (10, 7), dpi = dpi)\n",
    "    plt.title(\"SNPs sorted by logit-variance\")\n",
    "    plt.plot(np.arange(np.sum(self.SNP_DPmean_filter)) + 1, np.flip(np.sort((self.SNP_logit_var[self.SNP_DPmean_filter]))))\n",
    "    plt.ylabel(\"Logit-variance of SNP\")\n",
    "    plt.xlabel(\"SNP\")\n",
    "    plt.axhline(y = self.SNP_logit_var_threshold, color = 'r', linestyle = '-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f56842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VAE(self, num_epoch, stepsize, z_dim, beta, num_batch):\n",
    "    \n",
    "    print(\"Start training VAE.\")\n",
    "    \n",
    "    if z_dim == None:\n",
    "        \n",
    "        z_dim = int(np.min((np.ceil(self.cell_total / 2), np.ceil(self.SNP_total / 2))))\n",
    "    \n",
    "    loss_fn = nn.BCELoss(reduction = 'none')\n",
    "    \n",
    "    AF_DP_combined = torch.cat((self.AF_filtered, torch.tensor(self.DP_filtered)), 1).float()\n",
    "    cell_SNPread_filtered = np.count_nonzero(self.DP_filtered, 1)\n",
    "    cell_SNPread_weight = torch.tensor(np.outer(cell_SNPread_filtered, np.ones(z_dim))).float()\n",
    "    \n",
    "    data_loader = DataLoader(AF_DP_combined, int(np.ceil(self.cell_total / num_batch)), shuffle = True, generator = torch.Generator(device = 'cuda'))\n",
    "    \n",
    "    if self.SNPread == \"normalized\" and self.cell_weight == \"unnormalized\":\n",
    "    \n",
    "        model = VAE_normalized(self.SNP_total, z_dim)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = stepsize)\n",
    "\n",
    "        cost_total = np.empty(num_epoch)\n",
    "        cost_recon = np.empty(num_epoch)\n",
    "        cost_div = np.empty(num_epoch)\n",
    "\n",
    "        for epoch in range(num_epoch):\n",
    "\n",
    "            for batch, x in enumerate(data_loader):\n",
    "\n",
    "                cell_SNPread_filtered_batch = np.count_nonzero(x[:, self.SNP_total:].cpu().numpy(), 1)\n",
    "                cell_SNPread_weight_batch = torch.tensor(np.outer(cell_SNPread_filtered_batch, np.ones(z_dim))).float()\n",
    "\n",
    "                x_reconst_mu, mu, log_var = model(x[:, :self.SNP_total], cell_SNPread_weight_batch)\n",
    "                kl_div = - 0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "                recon_loss = torch.sum(loss_fn(x_reconst_mu, x[:, :self.SNP_total]) * x[:, self.SNP_total:]) / torch.tensor(np.sum(cell_SNPread_filtered_batch))\n",
    "                loss_total = recon_loss + beta * kl_div\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            x_reconst_mu, mu, log_var = model(self.AF_filtered, cell_SNPread_weight)\n",
    "            kl_div = - 0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            recon_loss = torch.sum(loss_fn(x_reconst_mu, AF_DP_combined[:, :self.SNP_total]) * AF_DP_combined[:, self.SNP_total:]) / torch.tensor(np.sum(cell_SNPread_filtered))\n",
    "            loss_total = recon_loss + beta * kl_div\n",
    "            \n",
    "            if ((epoch + 1) % 10) == 0:\n",
    "                \n",
    "                if (epoch + 1) <= 100 or ((epoch + 1) % 100) == 0:\n",
    "\n",
    "                    print(\"Epoch[{}/{}], Cost: {:.6f}\".format(epoch + 1, num_epoch, loss_total))\n",
    "\n",
    "            cost_total[epoch] = loss_total\n",
    "            cost_recon[epoch] = recon_loss\n",
    "            cost_div[epoch] = kl_div\n",
    "        \n",
    "        latent = model.encode(self.AF_filtered, cell_SNPread_weight)[0].detach().cpu().numpy()\n",
    "            \n",
    "    elif self.SNPread == \"unnormalized\" and self.cell_weight == \"unnormalized\":\n",
    "        \n",
    "        model = VAE_unnormalized(self.SNP_total, z_dim)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = stepsize)\n",
    "\n",
    "        cost_total = np.empty(num_epoch)\n",
    "        cost_recon = np.empty(num_epoch)\n",
    "        cost_div = np.empty(num_epoch)\n",
    "\n",
    "        for epoch in range(num_epoch):\n",
    "\n",
    "            for batch, x in enumerate(data_loader):\n",
    "                \n",
    "                cell_SNPread_filtered_batch = np.count_nonzero(x[:, self.SNP_total:].cpu().numpy(), 1)\n",
    "\n",
    "                x_reconst_mu, mu, log_var = model(x[:, :self.SNP_total])\n",
    "                kl_div = - 0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "                recon_loss = torch.sum(loss_fn(x_reconst_mu, x[:, :self.SNP_total]) * x[:, self.SNP_total:]) / torch.tensor(np.sum(cell_SNPread_filtered_batch))\n",
    "                loss_total = recon_loss + beta * kl_div\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            x_reconst_mu, mu, log_var = model(self.AF_filtered)\n",
    "            kl_div = - 0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            recon_loss = torch.sum(loss_fn(x_reconst_mu, AF_DP_combined[:, :self.SNP_total]) * AF_DP_combined[:, self.SNP_total:]) / torch.tensor(np.sum(cell_SNPread_filtered))\n",
    "            loss_total = recon_loss + beta * kl_div\n",
    "            \n",
    "            if ((epoch + 1) % 10) == 0:\n",
    "                \n",
    "                if (epoch + 1) <= 100 or ((epoch + 1) % 100) == 0:\n",
    "\n",
    "                    print(\"Epoch[{}/{}], Cost: {:.6f}\".format(epoch + 1, num_epoch, loss_total))\n",
    "\n",
    "            cost_total[epoch] = loss_total\n",
    "            cost_recon[epoch] = recon_loss\n",
    "            cost_div[epoch] = kl_div\n",
    "            \n",
    "        latent = model.encode(self.AF_filtered)[0].detach().cpu().numpy()\n",
    "        \n",
    "    elif self.SNPread == \"normalized\" and self.cell_weight == \"normalized\":\n",
    "    \n",
    "        model = VAE_normalized(self.SNP_total, z_dim)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = stepsize)\n",
    "\n",
    "        cost_total = np.empty(num_epoch)\n",
    "        cost_recon = np.empty(num_epoch)\n",
    "        cost_div = np.empty(num_epoch)\n",
    "\n",
    "        for epoch in range(num_epoch):\n",
    "\n",
    "            for batch, x in enumerate(data_loader):\n",
    "\n",
    "                cell_SNPread_filtered_batch = np.count_nonzero(x[:, self.SNP_total:].cpu().numpy(), 1)\n",
    "                cell_SNPread_weight_batch = torch.tensor(np.outer(cell_SNPread_filtered_batch, np.ones(z_dim))).float()\n",
    "\n",
    "                x_reconst_mu, mu, log_var = model(x[:, :self.SNP_total], cell_SNPread_weight_batch)\n",
    "                kl_div = - 0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "                recon_loss = torch.mean(torch.sum(loss_fn(x_reconst_mu, x[:, :self.SNP_total]) * x[:, self.SNP_total:], 1) / torch.tensor(cell_SNPread_filtered_batch))\n",
    "                loss_total = recon_loss + beta * kl_div\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            x_reconst_mu, mu, log_var = model(self.AF_filtered, cell_SNPread_weight)\n",
    "            kl_div = - 0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            recon_loss = torch.mean(torch.sum(loss_fn(x_reconst_mu, AF_DP_combined[:, :self.SNP_total]) * AF_DP_combined[:, self.SNP_total:], 1) / torch.tensor(self.cell_SNPread_filtered))\n",
    "            loss_total = recon_loss + beta * kl_div\n",
    "            \n",
    "            if ((epoch + 1) % 10) == 0:\n",
    "                \n",
    "                if (epoch + 1) <= 100 or ((epoch + 1) % 100) == 0:\n",
    "\n",
    "                    print(\"Epoch[{}/{}], Cost: {:.6f}\".format(epoch + 1, num_epoch, loss_total))\n",
    "\n",
    "            cost_total[epoch] = loss_total\n",
    "            cost_recon[epoch] = recon_loss\n",
    "            cost_div[epoch] = kl_div\n",
    "        \n",
    "        latent = model.encode(self.AF_filtered, cell_SNPread_weight)[0].detach().cpu().numpy()\n",
    "        \n",
    "    elif self.SNPread == \"unnormalized\" and self.cell_weight == \"normalized\":\n",
    "        \n",
    "        model = VAE_unnormalized(self.SNP_total, z_dim)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = stepsize)\n",
    "\n",
    "        cost_total = np.empty(num_epoch)\n",
    "        cost_recon = np.empty(num_epoch)\n",
    "        cost_div = np.empty(num_epoch)\n",
    "\n",
    "        for epoch in range(num_epoch):\n",
    "\n",
    "            for batch, x in enumerate(data_loader):\n",
    "                \n",
    "                cell_SNPread_filtered_batch = np.count_nonzero(x[:, self.SNP_total:].cpu().numpy(), 1)\n",
    "\n",
    "                x_reconst_mu, mu, log_var = model(x[:, :self.SNP_total])\n",
    "                kl_div = - 0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "                recon_loss = torch.mean(torch.sum(loss_fn(x_reconst_mu, x[:, :self.SNP_total]) * x[:, self.SNP_total:], 1) / torch.tensor(cell_SNPread_filtered_batch))\n",
    "                loss_total = recon_loss + beta * kl_div\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            x_reconst_mu, mu, log_var = model(self.AF_filtered)\n",
    "            kl_div = - 0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            recon_loss = torch.mean(torch.sum(loss_fn(x_reconst_mu, AF_DP_combined[:, :self.SNP_total]) * AF_DP_combined[:, self.SNP_total:], 1) / torch.tensor(self.cell_SNPread_filtered))\n",
    "            loss_total = recon_loss + beta * kl_div\n",
    "\n",
    "            if ((epoch + 1) % 10) == 0:\n",
    "                \n",
    "                if (epoch + 1) <= 100 or ((epoch + 1) % 100) == 0:\n",
    "\n",
    "                    print(\"Epoch[{}/{}], Cost: {:.6f}\".format(epoch + 1, num_epoch, loss_total))\n",
    "\n",
    "            cost_total[epoch] = loss_total\n",
    "            cost_recon[epoch] = recon_loss\n",
    "            cost_div[epoch] = kl_div\n",
    "            \n",
    "        latent = model.encode(self.AF_filtered)[0].detach().cpu().numpy()\n",
    "\n",
    "    self.num_epoch = num_epoch\n",
    "    self.stepsize = stepsize\n",
    "    self.z_dim = z_dim\n",
    "    self.beta = beta\n",
    "    self.num_batch = num_batch\n",
    "    self.cell_SNPread_filtered = cell_SNPread_filtered\n",
    "    self.model = model\n",
    "    self.cost_total = cost_total\n",
    "    self.cost_recon = cost_recon\n",
    "    self.cost_div = cost_div\n",
    "    self.latent = latent\n",
    "    \n",
    "    print(\"Finish training VAE, training curve will be shown below.\")\n",
    "    \n",
    "    plt.figure(figsize = (10, 7))\n",
    "    plt.title(f\"Training curve of VAE in {num_epoch} epochs\")\n",
    "    plt.plot(np.arange(1, num_epoch + 1), cost_total)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Start learning PCA and UMAP of latent space in VAE.\")\n",
    "    \n",
    "    pair_latent = squareform(pdist(latent))\n",
    "    \n",
    "    pca = PCA()\n",
    "    pca.fit(self.latent)\n",
    "    pc = pca.fit_transform(self.latent)\n",
    "    \n",
    "    reducer_2d = umap.UMAP(n_components = 2)\n",
    "    embedding_2d = reducer_2d.fit_transform(self.latent)\n",
    "    pair_embedding_2d = squareform(pdist(embedding_2d))\n",
    "    \n",
    "    if z_dim >= 3:\n",
    "    \n",
    "        reducer_3d = umap.UMAP(n_components = 3)\n",
    "        embedding_3d = reducer_3d.fit_transform(self.latent)\n",
    "        pair_embedding_3d = squareform(pdist(embedding_3d))\n",
    "    \n",
    "    print(\"Finish learning, PCA and UMAP of latent space will be shown below.\")\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(12, 5)\n",
    "    \n",
    "    axs[0].set_title(\"Scatter plot of PCA\")\n",
    "    axs[0].scatter(pc[:, 0], pc[:, 1], s = 5, color = \"black\")\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    axs[1].set_title(\"Scatter plot of UMAP\")\n",
    "    axs[1].scatter(embedding_2d[:, 0], embedding_2d[:, 1], s = 5, color = \"black\")\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    xlim_pc = axs[0].get_xlim()\n",
    "    ylim_pc = axs[0].get_ylim()\n",
    "    xlim_embedding_2d = axs[1].get_xlim()\n",
    "    ylim_embedding_2d = axs[1].get_ylim()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(12, 5)\n",
    "\n",
    "    axs[0].set_title(\"Density plot of PCA\")\n",
    "    H_pc = axs[0].hist2d(pc[:, 0], pc[:, 1], bins = (200, 200), cmap = plt.cm.jet, range = np.array([xlim_pc, ylim_pc]))\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "    fig.colorbar(H_pc[3], ax = axs[0])\n",
    "    \n",
    "    vmin_pc = np.min(H_pc[0])\n",
    "    vmax_pc = np.max(H_pc[0])\n",
    "    \n",
    "    axs[1].set_title(\"Density plot of UMAP\")\n",
    "    H_embedding_2d = axs[1].hist2d(embedding_2d[:, 0], embedding_2d[:, 1], bins = (200, 200), cmap = plt.cm.jet, range = np.array([xlim_embedding_2d, ylim_embedding_2d]))\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "    fig.colorbar(H_embedding_2d[3], ax = axs[1])\n",
    "    \n",
    "    vmin_embedding_2d = np.min(H_embedding_2d[0])\n",
    "    vmax_embedding_2d = np.max(H_embedding_2d[0])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    self.pair_latent = pair_latent\n",
    "    self.pc = pc\n",
    "    self.embedding_2d = embedding_2d\n",
    "    self.pair_embedding_2d = pair_embedding_2d\n",
    "    \n",
    "    if z_dim >= 3:\n",
    "        \n",
    "        self.embedding_3d = embedding_3d\n",
    "        self.pair_embedding_3d = pair_embedding_3d\n",
    "        \n",
    "    self.xlim_pc = xlim_pc\n",
    "    self.ylim_pc = ylim_pc\n",
    "    self.xlim_embedding_2d = xlim_embedding_2d\n",
    "    self.ylim_embedding_2d = ylim_embedding_2d\n",
    "    self.vmin_pc = vmin_pc\n",
    "    self.vmax_pc = vmax_pc\n",
    "    self.vmin_embedding_2d = vmin_embedding_2d\n",
    "    self.vmax_embedding_2d = vmax_embedding_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_training(self, dpi):\n",
    "    \n",
    "    print(\"Training curve will be shown below.\")\n",
    "    \n",
    "    plt.figure(figsize = (10, 7), dpi = dpi)\n",
    "    plt.title(f\"Training curve of VAE in {self.num_epoch} epochs\")\n",
    "    plt.plot(np.arange(1, self.num_epoch + 1), self.cost_total)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"PCA and UMAP of latent space will be shown below.\")\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, dpi = dpi)\n",
    "    fig.set_size_inches(12, 5)\n",
    "    \n",
    "    axs[0].set_title(\"Scatter plot of PCA\")\n",
    "    axs[0].scatter(self.pc[:, 0], self.pc[:, 1], s = 5, color = \"black\")\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    axs[1].set_title(\"Scatter plot of UMAP\")\n",
    "    axs[1].scatter(self.embedding_2d[:, 0], self.embedding_2d[:, 1], s = 5, color = \"black\")\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, dpi = dpi)\n",
    "    fig.set_size_inches(12, 5)\n",
    "\n",
    "    axs[0].set_title(\"Density plot of PCA\")\n",
    "    H_pc = axs[0].hist2d(self.pc[:, 0], self.pc[:, 1], bins = (200, 200), cmap = plt.cm.jet, range = np.array([self.xlim_pc, self.ylim_pc]))\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "    fig.colorbar(H_pc[3], ax = axs[0])\n",
    "    \n",
    "    axs[1].set_title(\"Density plot of UMAP\")\n",
    "    H_embedding_2d = axs[1].hist2d(self.embedding_2d[:, 0], self.embedding_2d[:, 1], bins = (200, 200), cmap = plt.cm.jet, range = np.array([self.xlim_embedding_2d, self.ylim_embedding_2d]))\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "    fig.colorbar(H_embedding_2d[3], ax = axs[1])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854fa329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_retrain(self):\n",
    "    \n",
    "    reducer_2d = umap.UMAP(n_components = 2)\n",
    "    embedding_2d = reducer_2d.fit_transform(self.latent)\n",
    "    pair_embedding_2d = squareform(pdist(embedding_2d))\n",
    "    \n",
    "    if self.z_dim >= 3:\n",
    "    \n",
    "        reducer_3d = umap.UMAP(n_components = 3)\n",
    "        embedding_3d = reducer_3d.fit_transform(self.latent)\n",
    "        pair_embedding_3d = squareform(pdist(embedding_3d))\n",
    "        \n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(6, 5)\n",
    "\n",
    "    axs.set_title(\"Scatter plot of UMAP\")\n",
    "    axs.scatter(embedding_2d[:, 0], embedding_2d[:, 1], s = 5, color = \"black\")\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    xlim_embedding_2d = axs.get_xlim()\n",
    "    ylim_embedding_2d = axs.get_ylim()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(6, 5)\n",
    "    \n",
    "    axs.set_title(\"Density plot of UMAP\")\n",
    "    H_embedding_2d = axs.hist2d(embedding_2d[:, 0], embedding_2d[:, 1], bins = (200, 200), cmap = plt.cm.jet, range = np.array([xlim_embedding_2d, ylim_embedding_2d]))\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "    fig.colorbar(H_embedding_2d[3], ax = axs)\n",
    "    \n",
    "    vmin_embedding_2d = np.min(H_embedding_2d[0])\n",
    "    vmax_embedding_2d = np.max(H_embedding_2d[0])\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "    self.embedding_2d = embedding_2d\n",
    "    self.pair_embedding_2d = pair_embedding_2d\n",
    "    \n",
    "    if self.z_dim >= 3:\n",
    "        \n",
    "        self.embedding_3d = embedding_3d\n",
    "        self.pair_embedding_3d = pair_embedding_3d\n",
    "        \n",
    "    self.xlim_embedding_2d = xlim_embedding_2d\n",
    "    self.ylim_embedding_2d = ylim_embedding_2d\n",
    "    self.vmin_embedding_2d = vmin_embedding_2d\n",
    "    self.vmax_embedding_2d = vmax_embedding_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1998ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_clustering(self, algorithm, max_cluster, resolution):\n",
    "    \n",
    "    self.algorithm = algorithm\n",
    "    \n",
    "    print(\"Start clustering.\")\n",
    "    \n",
    "    if algorithm == \"kmeans_umap3d\":\n",
    "    \n",
    "        scores = []\n",
    "        labels = []\n",
    "        distortions = []\n",
    "        centres = []\n",
    "\n",
    "        if self.z_dim >= 3:\n",
    "\n",
    "            if max_cluster < self.cell_total:\n",
    "\n",
    "                for m in np.arange(2, max_cluster + 1):\n",
    "\n",
    "                    kmeans = KMeans(n_clusters = m, n_init = 1).fit(self.embedding_3d)\n",
    "                    scores.append(silhouette_score(self.pair_embedding_3d, kmeans.labels_, metric = \"precomputed\"))\n",
    "                    labels.append(kmeans.labels_)\n",
    "                    distortions.append(kmeans.inertia_)\n",
    "                    centres.append(kmeans.cluster_centers_)\n",
    "                    print(\"{} clusters, Distortion: {:.6f}\".format(m, kmeans.inertia_))\n",
    "\n",
    "            elif max_cluster == self.cell_total:\n",
    "\n",
    "                for m in np.arange(2, max_cluster):\n",
    "\n",
    "                    kmeans = KMeans(n_clusters = m, n_init = 1).fit(self.embedding_3d)\n",
    "                    scores.append(silhouette_score(self.pair_embedding_3d, kmeans.labels_, metric = \"precomputed\"))\n",
    "                    labels.append(kmeans.labels_)\n",
    "                    distortions.append(kmeans.inertia_)\n",
    "                    centres.append(kmeans.cluster_centers_)\n",
    "                    print(\"{} clusters, Distortion: {:.6f}\".format(m, kmeans.inertia_))\n",
    "\n",
    "                scores.append(1)\n",
    "                labels.append(np.arange(0, self.cell_total))\n",
    "                distortions.append(0)\n",
    "                centres.append(self.embedding_3d)\n",
    "\n",
    "        elif self.z_dim == 2:\n",
    "\n",
    "            if max_cluster < self.cell_total:\n",
    "\n",
    "                for m in np.arange(2, max_cluster + 1):\n",
    "\n",
    "                    kmeans = KMeans(n_clusters = m, n_init = 1).fit(self.embedding_2d)\n",
    "                    scores.append(silhouette_score(self.pair_embedding_2d, kmeans.labels_, metric = \"precomputed\"))\n",
    "                    labels.append(kmeans.labels_)\n",
    "                    distortions.append(kmeans.inertia_)\n",
    "                    centres.append(kmeans.cluster_centers_)\n",
    "                    print(\"{} clusters, Distortion: {:.6f}\".format(m, kmeans.inertia_))\n",
    "\n",
    "            elif max_cluster == self.cell_total:\n",
    "\n",
    "                for m in np.arange(2, max_cluster):\n",
    "\n",
    "                    kmeans = KMeans(n_clusters = m, n_init = 1).fit(self.embedding_2d)\n",
    "                    scores.append(silhouette_score(self.pair_embedding_2d, kmeans.labels_, metric = \"precomputed\"))\n",
    "                    labels.append(kmeans.labels_)\n",
    "                    distortions.append(kmeans.inertia_)\n",
    "                    centres.append(kmeans.cluster_centers_)\n",
    "                    print(\"{} clusters, Distortion: {:.6f}\".format(m, kmeans.inertia_))\n",
    "\n",
    "                scores.append(1)\n",
    "                labels.append(np.arange(0, self.cell_total))\n",
    "                distortions.append(0)\n",
    "                centres.append(self.embedding_2d)\n",
    "\n",
    "        self.max_cluster = max_cluster\n",
    "        self.scores = scores\n",
    "        self.labels = labels\n",
    "        self.distortions = distortions\n",
    "        self.centres = centres\n",
    "\n",
    "        print(\"Finish clustering, PCA, UMAP, distortion, silhouette score of K-means clustering will be shown below.\")\n",
    "\n",
    "        fig, axs = plt.subplots(1, max_cluster - 1)\n",
    "        fig.set_size_inches(6 * (max_cluster - 1), 5)\n",
    "        fig.suptitle(\"Scatter plot of PCA\")\n",
    "\n",
    "        for m in np.arange(2, max_cluster + 1):\n",
    "\n",
    "            clusters = []\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                    clusters.append(np.where(labels[m - 2] == g)[0])\n",
    "\n",
    "            colors = cm.rainbow(np.linspace(0, 1, m))\n",
    "\n",
    "            axs[m - 2].set_title(str(m) + \" clusters\")\n",
    "            axs[m - 2].set_xticks([])\n",
    "            axs[m - 2].set_yticks([])\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                axs[m - 2].scatter(self.pc[clusters[g], 0], self.pc[clusters[g], 1], s = 5, color = colors[g])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, max_cluster - 1)\n",
    "        fig.set_size_inches(6 * (max_cluster - 1), 5)\n",
    "        fig.suptitle(\"Scatter plot of UMAP\")\n",
    "\n",
    "        for m in np.arange(2, max_cluster + 1):\n",
    "\n",
    "            clusters = []\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                    clusters.append(np.where(labels[m - 2] == g)[0])\n",
    "\n",
    "            colors = cm.rainbow(np.linspace(0, 1, m))\n",
    "\n",
    "            axs[m - 2].set_title(str(m) + \" clusters\")\n",
    "            axs[m - 2].set_xticks([])\n",
    "            axs[m - 2].set_yticks([])\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                axs[m - 2].scatter(self.embedding_2d[clusters[g], 0], self.embedding_2d[clusters[g], 1], s = 5, color = colors[g])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(12, 5)\n",
    "\n",
    "        axs[0].set_title(\"Distortion\")\n",
    "        axs[0].plot(np.arange(2, max_cluster + 1), distortions)\n",
    "        axs[0].set_xlabel(\"Number of clusters\")    \n",
    "\n",
    "        axs[1].set_title(\"Silhouette score\")\n",
    "        axs[1].plot(np.arange(2, max_cluster + 1), scores)\n",
    "        axs[1].set_xlabel(\"Number of clusters\")\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    elif algorithm == \"kmeans_full\":\n",
    "    \n",
    "        scores = []\n",
    "        labels = []\n",
    "        distortions = []\n",
    "        centres = []\n",
    "\n",
    "        if max_cluster < self.cell_total:\n",
    "\n",
    "            for m in np.arange(2, max_cluster + 1):\n",
    "\n",
    "                kmeans = KMeans(n_clusters = m, n_init = 1).fit(self.latent)\n",
    "                scores.append(silhouette_score(self.pair_latent, kmeans.labels_, metric = \"precomputed\"))\n",
    "                labels.append(kmeans.labels_)\n",
    "                distortions.append(kmeans.inertia_)\n",
    "                centres.append(kmeans.cluster_centers_)\n",
    "                print(\"{} clusters, Distortion: {:.6f}\".format(m, kmeans.inertia_))\n",
    "\n",
    "        elif max_cluster == self.cell_total:\n",
    "\n",
    "            for m in np.arange(2, max_cluster):\n",
    "\n",
    "                kmeans = KMeans(n_clusters = m, n_init = 1).fit(self.latent)\n",
    "                scores.append(silhouette_score(self.pair_latent, kmeans.labels_, metric = \"precomputed\"))\n",
    "                labels.append(kmeans.labels_)\n",
    "                distortions.append(kmeans.inertia_)\n",
    "                centres.append(kmeans.cluster_centers_)\n",
    "                print(\"{} clusters, Distortion: {:.6f}\".format(m, kmeans.inertia_))\n",
    "\n",
    "            scores.append(1)\n",
    "            labels.append(np.arange(0, self.cell_total))\n",
    "            distortions.append(0)\n",
    "            centres.append(self.embedding_3d)\n",
    "\n",
    "        self.max_cluster = max_cluster\n",
    "        self.scores = scores\n",
    "        self.labels = labels\n",
    "        self.distortions = distortions\n",
    "        self.centres = centres\n",
    "\n",
    "        print(\"Finish clustering, PCA, UMAP, distortion, silhouette score of K-means clustering will be shown below.\")\n",
    "\n",
    "        fig, axs = plt.subplots(1, max_cluster - 1)\n",
    "        fig.set_size_inches(6 * (max_cluster - 1), 5)\n",
    "        fig.suptitle(\"Scatter plot of PCA\")\n",
    "\n",
    "        for m in np.arange(2, max_cluster + 1):\n",
    "\n",
    "            clusters = []\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                    clusters.append(np.where(labels[m - 2] == g)[0])\n",
    "\n",
    "            colors = cm.rainbow(np.linspace(0, 1, m))\n",
    "\n",
    "            axs[m - 2].set_title(str(m) + \" clusters\")\n",
    "            axs[m - 2].set_xticks([])\n",
    "            axs[m - 2].set_yticks([])\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                axs[m - 2].scatter(self.pc[clusters[g], 0], self.pc[clusters[g], 1], s = 5, color = colors[g])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, max_cluster - 1)\n",
    "        fig.set_size_inches(6 * (max_cluster - 1), 5)\n",
    "        fig.suptitle(\"Scatter plot of UMAP\")\n",
    "\n",
    "        for m in np.arange(2, max_cluster + 1):\n",
    "\n",
    "            clusters = []\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                    clusters.append(np.where(labels[m - 2] == g)[0])\n",
    "\n",
    "            colors = cm.rainbow(np.linspace(0, 1, m))\n",
    "\n",
    "            axs[m - 2].set_title(str(m) + \" clusters\")\n",
    "            axs[m - 2].set_xticks([])\n",
    "            axs[m - 2].set_yticks([])\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                axs[m - 2].scatter(self.embedding_2d[clusters[g], 0], self.embedding_2d[clusters[g], 1], s = 5, color = colors[g])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(12, 5)\n",
    "\n",
    "        axs[0].set_title(\"Distortion\")\n",
    "        axs[0].plot(np.arange(2, max_cluster + 1), distortions)\n",
    "        axs[0].set_xlabel(\"Number of clusters\")    \n",
    "\n",
    "        axs[1].set_title(\"Silhouette score\")\n",
    "        axs[1].plot(np.arange(2, max_cluster + 1), scores)\n",
    "        axs[1].set_xlabel(\"Number of clusters\")\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    elif algorithm == \"leiden_full\":\n",
    "        \n",
    "        adata_latent = ad.AnnData(self.latent)\n",
    "        \n",
    "        sc.tl.pca(adata_latent, svd_solver = \"arpack\")\n",
    "        sc.pp.neighbors(adata_latent)\n",
    "        sc.tl.leiden(adata_latent, resolution = resolution)\n",
    "        \n",
    "        self.adata_latent = adata_latent\n",
    "        \n",
    "        print(\"Finish clustering.\")\n",
    "        \n",
    "    elif algorithm == \"leiden_umap3d\":\n",
    "        \n",
    "        adata_embedding_3d = ad.AnnData(self.embedding_3d)\n",
    "        \n",
    "        sc.pp.neighbors(adata_embedding_3d)\n",
    "        sc.tl.leiden(adata_embedding_3d, resolution = resolution)\n",
    "        \n",
    "        self.adata_embedding_3d = adata_embedding_3d\n",
    "        \n",
    "        print(\"Finish clustering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_clustering(self, dpi):\n",
    "    \n",
    "    if self.algorithm == \"kmeans_umap3d\" or self.algorithm == \"kmeans_full\":\n",
    "    \n",
    "        print(\"PCA, UMAP, distortion, silhouette score of K-means clustering will be shown below.\")\n",
    "\n",
    "        fig, axs = plt.subplots(1, self.max_cluster - 1, dpi = dpi)\n",
    "        fig.set_size_inches(6 * (self.max_cluster - 1), 5)\n",
    "        fig.suptitle(\"Scatter plot of PCA\")\n",
    "\n",
    "        for m in np.arange(2, self.max_cluster + 1):\n",
    "\n",
    "            clusters = []\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                    clusters.append(np.where(self.labels[m - 2] == g)[0])\n",
    "\n",
    "            colors = cm.rainbow(np.linspace(0, 1, m))\n",
    "\n",
    "            axs[m - 2].set_title(str(m) + \" clusters\")\n",
    "            axs[m - 2].set_xticks([])\n",
    "            axs[m - 2].set_yticks([])\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                axs[m - 2].scatter(self.pc[clusters[g], 0], self.pc[clusters[g], 1], s = 5, color = colors[g])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, self.max_cluster - 1, dpi = dpi)\n",
    "        fig.set_size_inches(6 * (self.max_cluster - 1), 5)\n",
    "        fig.suptitle(\"Scatter plot of UMAP\")\n",
    "\n",
    "        for m in np.arange(2, self.max_cluster + 1):\n",
    "\n",
    "            clusters = []\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                    clusters.append(np.where(self.labels[m - 2] == g)[0])\n",
    "\n",
    "            colors = cm.rainbow(np.linspace(0, 1, m))\n",
    "\n",
    "            axs[m - 2].set_title(str(m) + \" clusters\")\n",
    "            axs[m - 2].set_xticks([])\n",
    "            axs[m - 2].set_yticks([])\n",
    "\n",
    "            for g in range(m):\n",
    "\n",
    "                axs[m - 2].scatter(self.embedding_2d[clusters[g], 0], self.embedding_2d[clusters[g], 1], s = 5, color = colors[g])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, dpi = dpi)\n",
    "        fig.set_size_inches(12, 5)\n",
    "\n",
    "        axs[0].set_title(\"Distortion\")\n",
    "        axs[0].plot(np.arange(2, self.max_cluster + 1), self.distortions)\n",
    "        axs[0].set_xlabel(\"Number of clusters\")    \n",
    "\n",
    "        axs[1].set_title(\"Silhouette score\")\n",
    "        axs[1].plot(np.arange(2, self.max_cluster + 1), self.scores)\n",
    "        axs[1].set_xlabel(\"Number of clusters\")\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    elif self.algorithm == \"leiden_umap3d\" or self.algorithm == \"leiden_full\":\n",
    "        \n",
    "        print(\"Nothing to be shown.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree(self, cluster_no, pair_no, SNP_no, bad_color, cmap_heatmap):\n",
    "    \n",
    "    print(\"PCA and UMAP of individual clusters will be shown below.\")\n",
    "    \n",
    "    if self.algorithm == \"kmeans_umap3d\" or self.algorithm == \"kmeans_full\":\n",
    "    \n",
    "        assigned_label = self.labels[cluster_no - 2]\n",
    "        \n",
    "    elif self.algorithm == \"leiden_full\":\n",
    "        \n",
    "        assigned_label = np.array(self.adata_latent.obs[\"leiden\"].to_numpy(), dtype = int)\n",
    "        cluster_no = int(np.max(assigned_label) + 1)\n",
    "        \n",
    "    elif self.algorithm == \"leiden_umap3d\":\n",
    "        \n",
    "        assigned_label = np.array(self.adata_embedding_3d.obs[\"leiden\"].to_numpy(), dtype = int)\n",
    "        cluster_no = int(np.max(assigned_label) + 1)\n",
    "    \n",
    "    clusters = []\n",
    "    \n",
    "    for g in range(cluster_no):\n",
    "\n",
    "            clusters.append(np.where(assigned_label == g)[0])\n",
    "    \n",
    "    colors = cm.rainbow(np.linspace(0, 1, cluster_no))\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(12, 5)\n",
    "    \n",
    "    axs[0].set_title(\"Scatter plot of PCA\")\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    for g in range(cluster_no):\n",
    "\n",
    "        axs[0].scatter(self.pc[clusters[g], 0], self.pc[clusters[g], 1], s = 5, color = colors[g])\n",
    "\n",
    "    axs[1].set_title(\"Scatter plot of UMAP\")\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    for g in range(cluster_no):\n",
    "\n",
    "        axs[1].scatter(self.embedding_2d[clusters[g], 0], self.embedding_2d[clusters[g], 1], s = 5, color = colors[g])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, cluster_no)\n",
    "    fig.set_size_inches(6 * cluster_no, 5)\n",
    "    fig.suptitle(\"Scatter plot of PCA\")\n",
    "    \n",
    "    for m in range(cluster_no):\n",
    "        \n",
    "        axs[m].set_title(\"Cluster \" + str(m))\n",
    "        axs[m].scatter(self.pc[:, 0], self.pc[:, 1], s = 5, color = 'black')\n",
    "        axs[m].scatter(self.pc[clusters[m], 0], self.pc[clusters[m], 1], s = 5, color = colors[m])\n",
    "        axs[m].set_xticks([])\n",
    "        axs[m].set_yticks([])\n",
    "        axs[m].set_xlim(self.xlim_pc)\n",
    "        axs[m].set_ylim(self.ylim_pc)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, cluster_no)\n",
    "    fig.set_size_inches(6 * cluster_no, 5)\n",
    "    fig.suptitle(\"Scatter plot of UMAP\")\n",
    "    \n",
    "    for m in range(cluster_no):\n",
    "        \n",
    "        axs[m].set_title(\"Cluster \" + str(m))\n",
    "        axs[m].scatter(self.embedding_2d[:, 0], self.embedding_2d[:, 1], s = 5, color = 'black')\n",
    "        axs[m].scatter(self.embedding_2d[clusters[m], 0], self.embedding_2d[clusters[m], 1], s = 5, color = colors[m])\n",
    "        axs[m].set_xticks([])\n",
    "        axs[m].set_yticks([])\n",
    "        axs[m].set_xlim(self.xlim_embedding_2d)\n",
    "        axs[m].set_ylim(self.ylim_embedding_2d)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, cluster_no)\n",
    "    fig.set_size_inches(6 * cluster_no, 5)\n",
    "    fig.suptitle(\"Density plot of PCA\")\n",
    "    \n",
    "    for m in range(cluster_no):\n",
    "        \n",
    "        axs[m].set_title(\"Cluster \" + str(m))\n",
    "        axs[m].hist2d(self.pc[clusters[m], 0], self.pc[clusters[m], 1], bins = (200, 200), cmap = plt.cm.jet, range = np.array([self.xlim_pc, self.ylim_pc]), vmin = self.vmin_pc, vmax = self.vmax_pc)\n",
    "        axs[m].set_xticks([])\n",
    "        axs[m].set_yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, cluster_no)\n",
    "    fig.set_size_inches(6 * cluster_no, 5)\n",
    "    fig.suptitle(\"Density plot of UMAP\")\n",
    "    \n",
    "    for m in range(cluster_no):\n",
    "        \n",
    "        axs[m].set_title(\"Cluster \" + str(m))\n",
    "        axs[m].hist2d(self.embedding_2d[clusters[m], 0], self.embedding_2d[clusters[m], 1], bins = (200, 200), cmap = plt.cm.jet, range = np.array([self.xlim_embedding_2d, self.ylim_embedding_2d]), vmin = self.vmin_embedding_2d, vmax = self.vmax_embedding_2d)\n",
    "        axs[m].set_xticks([])\n",
    "        axs[m].set_yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    if self.z_dim >= 3:\n",
    "    \n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(12, 5)\n",
    "        axs1 = fig.add_subplot(121, projection = '3d')\n",
    "        axs2 = fig.add_subplot(122, projection = '3d')\n",
    "\n",
    "        axs1.set_title(\"Scatter plot of PCA\")\n",
    "        axs1.set_xticks([])\n",
    "        axs1.set_yticks([])\n",
    "        axs1.set_zticks([])\n",
    "\n",
    "        for g in range(cluster_no):\n",
    "\n",
    "            axs1.scatter(self.pc[clusters[g], 0], self.pc[clusters[g], 1], self.pc[clusters[g], 2], s = 5, color = colors[g])\n",
    "\n",
    "        axs2.set_title(\"Scatter plot of UMAP\")\n",
    "        axs2.set_xticks([])\n",
    "        axs2.set_yticks([])\n",
    "        axs2.set_zticks([])\n",
    "\n",
    "        for g in range(cluster_no):\n",
    "\n",
    "            axs2.scatter(self.embedding_3d[clusters[g], 0], self.embedding_3d[clusters[g], 1], self.embedding_3d[clusters[g], 2], s = 5, color = colors[g])\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    self.cluster_no = cluster_no\n",
    "    self.assigned_label = assigned_label\n",
    "    self.clusters = clusters\n",
    "    self.colors = colors\n",
    "    \n",
    "    cluster_size = []\n",
    "\n",
    "    for w in range(cluster_no):\n",
    "\n",
    "        cluster_size.append(clusters[w].shape[0])\n",
    "        \n",
    "    cluster_size = np.array(cluster_size)\n",
    "    cluster_size_sorted = np.sort(cluster_size)\n",
    "    \n",
    "    pair_no = int(np.min(np.array([pair_no, int(cluster_size_sorted[0] * cluster_size_sorted[1])])))\n",
    "    \n",
    "    pair_latent = squareform(pdist(self.latent))\n",
    "    pair_latent_cluster = np.empty((cluster_no, cluster_no))\n",
    "    pair_latent_cluster_neighbour = np.empty((cluster_no, cluster_no))\n",
    "\n",
    "    for t in range(cluster_no):\n",
    "\n",
    "        for g in range(cluster_no):\n",
    "\n",
    "            pair_latent_cluster[t, g] = np.mean(pair_latent[clusters[t], :][:, clusters[g]].flatten())\n",
    "            pair_latent_cluster_neighbour[t, g] = np.mean(np.sort(pair_latent[clusters[t], :][:, clusters[g]].flatten())[:pair_no])\n",
    "\n",
    "    for w in range(cluster_no):\n",
    "\n",
    "        pair_latent_cluster[w, w] = np.nan\n",
    "        pair_latent_cluster_neighbour[w, w] = np.nan\n",
    "\n",
    "    edge_length = []\n",
    "    edge_length_neighbour = [] \n",
    "    edge = []\n",
    "    connected = np.zeros(cluster_no)\n",
    "    connect_order = []\n",
    "\n",
    "    pair_nearest = np.unravel_index(np.nanargmin(pair_latent_cluster_neighbour), pair_latent_cluster_neighbour.shape)\n",
    "    edge_length.append(pair_latent_cluster[pair_nearest])\n",
    "    edge_length_neighbour.append(pair_latent_cluster_neighbour[pair_nearest])\n",
    "    edge.append(pair_nearest)\n",
    "    connected[pair_nearest[0]] = 1\n",
    "    connected[pair_nearest[1]] = 1\n",
    "    connect_order.append(pair_nearest[0])\n",
    "    connect_order.append(pair_nearest[1])\n",
    "\n",
    "    while np.sum(connected) < cluster_no:\n",
    "\n",
    "        search_space = pair_latent_cluster_neighbour[np.where(connected == 1)[0], :][:, np.where(connected == 0)[0]]\n",
    "        pair_nearest_search = np.unravel_index(np.argmin(search_space), search_space.shape)\n",
    "        pair_nearest = (np.where(connected == 1)[0][pair_nearest_search[0]], np.where(connected == 0)[0][pair_nearest_search[1]])\n",
    "        edge_length.append(pair_latent_cluster[pair_nearest])\n",
    "        edge_length_neighbour.append(pair_latent_cluster_neighbour[pair_nearest])\n",
    "        edge.append(pair_nearest)\n",
    "        connected[pair_nearest[1]] = 1\n",
    "        connect_order.append(pair_nearest[1])\n",
    "\n",
    "    edge_weight = 1 / (np.array(edge_length) ** 2)\n",
    "    edge_length_normalized = np.round(edge_length / np.sqrt(self.z_dim), decimals = 2)\n",
    "    \n",
    "    centre_2d = []\n",
    "\n",
    "    for w in range(cluster_no):\n",
    "    \n",
    "        centre_2d.append(list(np.mean(self.embedding_2d[clusters[w], :], 0)))\n",
    "    \n",
    "    centre_2d = np.array(centre_2d)\n",
    "\n",
    "    print(f\"Phylogenetic tree in latent space will be shown below.\")\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(6, 5)\n",
    "\n",
    "    axs.set_title(\"Phylogenetic tree on UMAP\")\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "\n",
    "    for g in range(cluster_no):\n",
    "\n",
    "        axs.scatter(self.embedding_2d[clusters[g], 0], self.embedding_2d[clusters[g], 1], s = 5, color = colors[g])\n",
    "    \n",
    "    for g in range(len(edge)):\n",
    "    \n",
    "        axs.plot([centre_2d[edge[g][0], 0], centre_2d[edge[g][1], 0]], [centre_2d[edge[g][0], 1], centre_2d[edge[g][1], 1]], linewidth = 3, color = \"black\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    for u in range(len(edge)):\n",
    "\n",
    "        graph.add_edge(edge[u][0], edge[u][1], weight = edge_weight[u], length = edge_length_normalized[u])\n",
    "\n",
    "    pos = nx.spring_layout(graph, iterations = 3000, weight = 'weight')\n",
    "\n",
    "    plt.figure(figsize = (26, 14)) \n",
    "    nx.draw(graph, pos, with_labels = True, font_weight = 'bold', node_size = cluster_size[connect_order], node_color = self.colors[connect_order])\n",
    "    nx.draw_networkx_edge_labels(graph, pos, nx.get_edge_attributes(graph, 'length'), rotate = False, alpha = 0.75)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    self.pair_no = pair_no\n",
    "    self.pair_latent = pair_latent\n",
    "    self.pair_latent_cluster = pair_latent_cluster\n",
    "    self.pair_latent_cluster_neighbour = pair_latent_cluster_neighbour\n",
    "    self.edge_length = edge_length\n",
    "    self.edge_length_neighbour = edge_length_neighbour\n",
    "    self.edge = edge\n",
    "    self.connect_order = connect_order\n",
    "    self.edge_weight = edge_weight\n",
    "    self.edge_length_normalized = edge_length_normalized\n",
    "    self.cluster_size = cluster_size\n",
    "    self.centre_2d = centre_2d\n",
    "    \n",
    "    SNP_no = np.min((self.SNP_total, SNP_no)).astype(int)\n",
    "    \n",
    "    SNP_cluster_logit_var = np.empty((cluster_no, self.SNP_total))\n",
    "    SNP_cluster_AF_filtered_missing_to_zero = np.empty((cluster_no, self.SNP_total))\n",
    "    centre_cluster = np.empty((cluster_no, self.z_dim))\n",
    "    \n",
    "    for m in range(cluster_no):\n",
    "        \n",
    "        SNP_cluster_logit_var[m, :] = torch.var(torch.logit(self.AF_filtered_missing_to_mean[clusters[m], :], eps = 0.01), 0).cpu().numpy()\n",
    "        SNP_cluster_AF_filtered_missing_to_zero[m, :] = np.mean(self.AF_filtered_missing_to_zero.cpu().numpy()[clusters[m], :], 0)\n",
    "        centre_cluster[m, :] = np.mean(self.latent[clusters[m], :], 0)\n",
    "    \n",
    "    ratio_logit_var = np.min(SNP_cluster_logit_var, 0) / self.SNP_logit_var[self.SNP_filter]\n",
    "    f_stat = np.clip(1 / ratio_logit_var, 1.001, 20)\n",
    "    df_bulk = self.cell_total - 1\n",
    "    df_cluster = np.array(list(map(lambda x: cluster_size[x], np.argmin(SNP_cluster_logit_var, 0)))) - 1\n",
    "    p_value = 1 - stats.f.cdf(f_stat, df_bulk, df_cluster)\n",
    "    SNP_cluster_AF_filtered_missing_to_zero_max = np.max(SNP_cluster_AF_filtered_missing_to_zero, 0)\n",
    "    \n",
    "    rank_SNP = np.argsort(p_value)\n",
    "    SNP_low_p_value_total = np.sum(np.log10(p_value) < -15.5)\n",
    "    \n",
    "    if SNP_low_p_value_total > 1:\n",
    "        \n",
    "        SNP_low_p_value = rank_SNP[:SNP_low_p_value_total]\n",
    "        \n",
    "        rank_SNP_low_p_value = np.flip(np.argsort(SNP_cluster_AF_filtered_missing_to_zero_max[SNP_low_p_value]))\n",
    "        rank_SNP[:SNP_low_p_value_total] = rank_SNP[:SNP_low_p_value_total][rank_SNP_low_p_value]\n",
    "        \n",
    "        self.SNP_low_p_value = SNP_low_p_value\n",
    "        self.rank_SNP_low_p_value = rank_SNP_low_p_value\n",
    "        \n",
    "    root = np.argmin(np.mean(centre_cluster ** 2, 1))\n",
    "    move = 0\n",
    "    edge_remain = edge.copy()\n",
    "    current_pos = root\n",
    "    cluster_order = [root]\n",
    "    history = []\n",
    "\n",
    "    while move < len(edge):\n",
    "\n",
    "        current_move = move\n",
    "\n",
    "        for w in range(len(edge_remain)):\n",
    "\n",
    "            if current_pos in edge_remain[w]:\n",
    "\n",
    "                history.append(current_pos)\n",
    "\n",
    "                if edge_remain[w][0] == current_pos:\n",
    "\n",
    "                    current_pos = edge_remain[w][1]\n",
    "\n",
    "                elif edge_remain[w][1] == current_pos:\n",
    "\n",
    "                    current_pos = edge_remain[w][0]\n",
    "\n",
    "                cluster_order.append(current_pos)\n",
    "                move = current_move + 1            \n",
    "                edge_remain.remove(edge_remain[w])     \n",
    "                break\n",
    "\n",
    "        if current_move == move:\n",
    "\n",
    "            current_pos = history[-1]\n",
    "            del history[-1]\n",
    "    \n",
    "    cell_sorted = np.empty(0)\n",
    "\n",
    "    for w in cluster_order:\n",
    "\n",
    "        cell_sorted = np.concatenate((cell_sorted, clusters[w]), axis = None).astype(int)\n",
    "        \n",
    "    AF_sorted = self.AF_filtered_missing_to_nan[cell_sorted, :][:, rank_SNP].T\n",
    "    \n",
    "    print(f\"SNP-allelic ratios of {self.cell_total} cells and {SNP_no} SNPs will be shown below.\")\n",
    "    \n",
    "    clus_colors = pd.Series(assigned_label[cell_sorted]).map(dict(zip(np.arange(0, cluster_no), colors)))\n",
    "    clus_colors.index = pd.RangeIndex(start = 1, stop = self.cell_total + 1, step = 1)\n",
    "    \n",
    "    cmap = cmap_heatmap \n",
    "    cmap.set_bad(bad_color)\n",
    "    \n",
    "    if self.is_VCF == True:\n",
    "        \n",
    "        fig = sns.clustermap(pd.DataFrame(AF_sorted[:SNP_no, :], index = self.VCF_filtered[\"TEXT\"].to_numpy()[rank_SNP][:SNP_no], columns = np.arange(1, self.cell_total + 1)), row_cluster = False, col_cluster = False, col_colors = clus_colors, figsize = (20, SNP_no * 0.6), cmap = cmap, vmin = 0, vmax = 1)\n",
    "    \n",
    "    elif self.is_VCF == False:\n",
    "        \n",
    "        fig = sns.clustermap(pd.DataFrame(AF_sorted[:SNP_no, :], index = self.VCF_filtered[0].to_numpy()[rank_SNP][:SNP_no], columns = np.arange(1, self.cell_total + 1)), row_cluster = False, col_cluster = False, col_colors = clus_colors, figsize = (20, SNP_no * 0.6), cmap = cmap, vmin = 0, vmax = 1)\n",
    "    \n",
    "    fig.ax_col_colors.set_xticks(moving_average(np.cumsum([0] + list(cluster_size[cluster_order])), 2))\n",
    "    fig.ax_col_colors.set_xticklabels(np.array(cluster_order))\n",
    "    fig.ax_col_colors.xaxis.set_tick_params(size = 0)\n",
    "    fig.ax_col_colors.xaxis.tick_top()\n",
    "    fig.ax_heatmap.set_xticklabels(fig.ax_heatmap.get_xmajorticklabels(), fontsize = 14)\n",
    "    plt.show()\n",
    "    \n",
    "    ratio_logit_var_ranked = ratio_logit_var[rank_SNP]\n",
    "    f_stat_ranked = f_stat[rank_SNP]\n",
    "    p_value_ranked = p_value[rank_SNP]\n",
    "    SNP_cluster_AF_filtered_missing_to_zero_max_ranked = SNP_cluster_AF_filtered_missing_to_zero_max[rank_SNP]\n",
    "    \n",
    "    print(\"SNPs sorted by lowest p-value will be shown below\")\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    fig.set_size_inches(10, 7)\n",
    "    fig.suptitle(\"SNPs sorted by lowest p-value\")\n",
    "\n",
    "    ax1.set_xlabel('SNP')\n",
    "    ax1.set_ylabel('F-statistic', color = 'tab:red')\n",
    "    ax1.plot(np.arange(self.SNP_total), f_stat_ranked, color = 'tab:red')\n",
    "    ax1.tick_params(axis = 'y', labelcolor = 'tab:red')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('log10(p-value)', color = 'tab:blue')\n",
    "    ax2.plot(np.arange(self.SNP_total), np.log10(p_value_ranked), color = 'tab:blue')\n",
    "    ax2.tick_params(axis = 'y', labelcolor = 'tab:blue')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    self.SNP_no = SNP_no\n",
    "    self.SNP_cluster_logit_var = SNP_cluster_logit_var\n",
    "    self.SNP_cluster_AF_filtered_missing_to_zero = SNP_cluster_AF_filtered_missing_to_zero\n",
    "    self.centre_cluster = centre_cluster\n",
    "    self.ratio_logit_var = ratio_logit_var\n",
    "    self.f_stat = f_stat\n",
    "    self.df_bulk = df_bulk\n",
    "    self.df_cluster = df_cluster\n",
    "    self.p_value = p_value\n",
    "    self.SNP_cluster_AF_filtered_missing_to_zero_max = SNP_cluster_AF_filtered_missing_to_zero_max\n",
    "    self.rank_SNP = rank_SNP\n",
    "    self.SNP_low_p_value_total = SNP_low_p_value_total\n",
    "    self.root = root\n",
    "    self.cluster_order = cluster_order\n",
    "    self.cell_sorted = cell_sorted\n",
    "    self.AF_sorted = AF_sorted\n",
    "    self.ratio_logit_var_ranked = ratio_logit_var_ranked\n",
    "    self.f_stat_ranked = f_stat_ranked\n",
    "    self.p_value_ranked = p_value_ranked\n",
    "    self.SNP_cluster_AF_filtered_missing_to_zero_max_ranked = SNP_cluster_AF_filtered_missing_to_zero_max_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe81d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_phylogeny(self, SNP_no, dpi, bad_color, fontsize_c, fontsize_x, fontsize_y, cmap_heatmap):\n",
    "    \n",
    "    if SNP_no == None:\n",
    "        \n",
    "        SNP_no = self.SNP_no\n",
    "        \n",
    "    print(\"PCA and UMAP of individual clusters will be shown below.\")\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, dpi = dpi)\n",
    "    fig.set_size_inches(12, 5)\n",
    "    \n",
    "    axs[0].set_title(\"Scatter plot of PCA\")\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    for g in range(self.cluster_no):\n",
    "\n",
    "        axs[0].scatter(self.pc[self.clusters[g], 0], self.pc[self.clusters[g], 1], s = 5, color = self.colors[g])\n",
    "\n",
    "    axs[1].set_title(\"Scatter plot of UMAP\")\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    for g in range(self.cluster_no):\n",
    "\n",
    "        axs[1].scatter(self.embedding_2d[self.clusters[g], 0], self.embedding_2d[self.clusters[g], 1], s = 5, color = self.colors[g])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, self.cluster_no, dpi = dpi)\n",
    "    fig.set_size_inches(6 * self.cluster_no, 5)\n",
    "    fig.suptitle(\"Scatter plot of PCA\")\n",
    "    \n",
    "    for m in range(self.cluster_no):\n",
    "        \n",
    "        axs[m].set_title(\"Cluster \" + str(m))\n",
    "        axs[m].scatter(self.pc[:, 0], self.pc[:, 1], s = 5, color = 'black')\n",
    "        axs[m].scatter(self.pc[self.clusters[m], 0], self.pc[self.clusters[m], 1], s = 5, color = self.colors[m])\n",
    "        axs[m].set_xticks([])\n",
    "        axs[m].set_yticks([])\n",
    "        axs[m].set_xlim(self.xlim_pc)\n",
    "        axs[m].set_ylim(self.ylim_pc)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, self.cluster_no, dpi = dpi)\n",
    "    fig.set_size_inches(6 * self.cluster_no, 5)\n",
    "    fig.suptitle(\"Scatter plot of UMAP\")\n",
    "    \n",
    "    for m in range(self.cluster_no):\n",
    "        \n",
    "        axs[m].set_title(\"Cluster \" + str(m))\n",
    "        axs[m].scatter(self.embedding_2d[:, 0], self.embedding_2d[:, 1], s = 5, color = 'black')\n",
    "        axs[m].scatter(self.embedding_2d[self.clusters[m], 0], self.embedding_2d[self.clusters[m], 1], s = 5, color = self.colors[m])\n",
    "        axs[m].set_xticks([])\n",
    "        axs[m].set_yticks([])\n",
    "        axs[m].set_xlim(self.xlim_embedding_2d)\n",
    "        axs[m].set_ylim(self.ylim_embedding_2d)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, self.cluster_no, dpi = dpi)\n",
    "    fig.set_size_inches(6 * self.cluster_no, 5)\n",
    "    fig.suptitle(\"Density plot of PCA\")\n",
    "    \n",
    "    for m in range(self.cluster_no):\n",
    "        \n",
    "        axs[m].set_title(\"Cluster \" + str(m))\n",
    "        axs[m].hist2d(self.pc[self.clusters[m], 0], self.pc[self.clusters[m], 1], bins = (200, 200), cmap = plt.cm.jet, range = np.array([self.xlim_pc, self.ylim_pc]), vmin = self.vmin_pc, vmax = self.vmax_pc)\n",
    "        axs[m].set_xticks([])\n",
    "        axs[m].set_yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, self.cluster_no, dpi = dpi)\n",
    "    fig.set_size_inches(6 * self.cluster_no, 5)\n",
    "    fig.suptitle(\"Density plot of UMAP\")\n",
    "    \n",
    "    for m in range(self.cluster_no):\n",
    "        \n",
    "        axs[m].set_title(\"Cluster \" + str(m))\n",
    "        axs[m].hist2d(self.embedding_2d[self.clusters[m], 0], self.embedding_2d[self.clusters[m], 1], bins = (200, 200), cmap = plt.cm.jet, range = np.array([self.xlim_embedding_2d, self.ylim_embedding_2d]), vmin = self.vmin_embedding_2d, vmax = self.vmax_embedding_2d)\n",
    "        axs[m].set_xticks([])\n",
    "        axs[m].set_yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    if self.z_dim >= 3:\n",
    "    \n",
    "        fig = plt.figure(dpi = dpi)\n",
    "        fig.set_size_inches(12, 5)\n",
    "        axs1 = fig.add_subplot(121, projection = '3d')\n",
    "        axs2 = fig.add_subplot(122, projection = '3d')\n",
    "\n",
    "        axs1.set_title(\"Scatter plot of PCA\")\n",
    "        axs1.set_xticks([])\n",
    "        axs1.set_yticks([])\n",
    "        axs1.set_zticks([])\n",
    "\n",
    "        for g in range(self.cluster_no):\n",
    "\n",
    "            axs1.scatter(self.pc[self.clusters[g], 0], self.pc[self.clusters[g], 1], self.pc[self.clusters[g], 2], s = 5, color = self.colors[g])\n",
    "\n",
    "        axs2.set_title(\"Scatter plot of UMAP\")\n",
    "        axs2.set_xticks([])\n",
    "        axs2.set_yticks([])\n",
    "        axs2.set_zticks([])\n",
    "\n",
    "        for g in range(self.cluster_no):\n",
    "\n",
    "            axs2.scatter(self.embedding_3d[self.clusters[g], 0], self.embedding_3d[self.clusters[g], 1], self.embedding_3d[self.clusters[g], 2], s = 5, color = self.colors[g])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Phylogenetic tree in latent space will be shown below.\")\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1, dpi = dpi)\n",
    "    fig.set_size_inches(6, 5)\n",
    "\n",
    "    axs.set_title(\"Phylogenetic tree on UMAP\")\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "\n",
    "    for g in range(self.cluster_no):\n",
    "\n",
    "        axs.scatter(self.embedding_2d[self.clusters[g], 0], self.embedding_2d[self.clusters[g], 1], s = 5, color = self.colors[g])\n",
    "    \n",
    "    for g in range(len(self.edge)):\n",
    "    \n",
    "        axs.plot([self.centre_2d[self.edge[g][0], 0], self.centre_2d[self.edge[g][1], 0]], [self.centre_2d[self.edge[g][0], 1], self.centre_2d[self.edge[g][1], 1]], linewidth = 3, color = \"black\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    for u in range(len(self.edge)):\n",
    "\n",
    "        graph.add_edge(self.edge[u][0], self.edge[u][1], weight = self.edge_weight[u], length = self.edge_length_normalized[u])\n",
    "\n",
    "    pos = nx.spring_layout(graph, iterations = 3000, weight = 'weight')\n",
    "\n",
    "    plt.figure(figsize = (26, 14), dpi = dpi) \n",
    "    nx.draw(graph, pos, with_labels = True, font_weight = 'bold', node_size = self.cluster_size[self.connect_order], node_color = self.colors[self.connect_order])\n",
    "    nx.draw_networkx_edge_labels(graph, pos, nx.get_edge_attributes(graph, 'length'), rotate = False, alpha = 0.75)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    SNP_no = np.min((self.SNP_total, SNP_no)).astype(int)\n",
    "    \n",
    "    print(f\"SNP-allelic ratios of {self.cell_total} cells and {SNP_no} SNPs will be shown below.\")\n",
    "    \n",
    "    clus_colors = pd.Series(self.assigned_label[self.cell_sorted]).map(dict(zip(np.arange(0, self.cluster_no), self.colors)))\n",
    "    clus_colors.index = pd.RangeIndex(start = 1, stop = self.cell_total + 1, step = 1)\n",
    "    \n",
    "    cmap = cmap_heatmap \n",
    "    cmap.set_bad(bad_color)\n",
    "    \n",
    "    if self.is_VCF == True:\n",
    "    \n",
    "        fig = sns.clustermap(pd.DataFrame(self.AF_sorted[:SNP_no, :], index = self.VCF_filtered[\"TEXT\"].to_numpy()[self.rank_SNP][:SNP_no], columns = np.arange(1, self.cell_total + 1)), row_cluster = False, col_cluster = False, col_colors = clus_colors, figsize = (20, SNP_no * 0.6), cmap = cmap, vmin = 0, vmax = 1)\n",
    "        \n",
    "    elif self.is_VCF == False:\n",
    "        \n",
    "        fig = sns.clustermap(pd.DataFrame(self.AF_sorted[:SNP_no, :], index = self.VCF_filtered[0].to_numpy()[self.rank_SNP][:SNP_no], columns = np.arange(1, self.cell_total + 1)), row_cluster = False, col_cluster = False, col_colors = clus_colors, figsize = (20, SNP_no * 0.6), cmap = cmap, vmin = 0, vmax = 1)\n",
    "    \n",
    "    fig.ax_col_colors.set_xticks(moving_average(np.cumsum([0] + list(self.cluster_size[self.cluster_order])), 2))\n",
    "    \n",
    "    if fontsize_c == None:\n",
    "        \n",
    "        fig.ax_col_colors.set_xticklabels(np.array(self.cluster_order))\n",
    "        \n",
    "    elif fontsize_c != None:\n",
    "        \n",
    "        fig.ax_col_colors.set_xticklabels(np.array(self.cluster_order), fontsize = fontsize_c)\n",
    "        \n",
    "    fig.ax_col_colors.xaxis.set_tick_params(size = 0)\n",
    "    fig.ax_col_colors.xaxis.tick_top()\n",
    "    \n",
    "    if fontsize_x != None:\n",
    "        \n",
    "        fig.ax_heatmap.set_xticklabels(fig.ax_heatmap.get_xmajorticklabels(), fontsize = fontsize_x)\n",
    "    \n",
    "    if fontsize_y != None:\n",
    "        \n",
    "        fig.ax_heatmap.set_yticklabels(fig.ax_heatmap.get_ymajorticklabels(), fontsize = fontsize_y)\n",
    "        \n",
    "    plt.gcf().set_dpi(dpi)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"SNPs sorted by lowest p-value will be shown below\")\n",
    "    \n",
    "    fig, ax1 = plt.subplots(dpi = dpi)\n",
    "    fig.set_size_inches(10, 7)\n",
    "    fig.suptitle(\"SNPs sorted by lowest p-value\")\n",
    "\n",
    "    ax1.set_xlabel('SNP')\n",
    "    ax1.set_ylabel('F-statistic', color = 'tab:red')\n",
    "    ax1.plot(np.arange(self.SNP_total), self.f_stat_ranked, color = 'tab:red')\n",
    "    ax1.tick_params(axis = 'y', labelcolor = 'tab:red')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('log10(p-value)', color = 'tab:blue')\n",
    "    ax2.plot(np.arange(self.SNP_total), np.log10(self.p_value_ranked), color = 'tab:blue')\n",
    "    ax2.tick_params(axis = 'y', labelcolor = 'tab:blue')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_AF(self, SNP_name, dpi):\n",
    "    \n",
    "    color_AF = cm.Reds(np.linspace(0, 1, 101))\n",
    "    \n",
    "    if is_VCF == True:\n",
    "        \n",
    "        AF_SNP = self.AF_filtered_missing_to_zero.cpu().numpy()[:, np.where(self.VCF_filtered[\"TEXT\"].to_numpy() == SNP_name)[0][0]]\n",
    "        \n",
    "    elif is_VCF == False:\n",
    "        \n",
    "        AF_SNP = self.AF_filtered_missing_to_zero.cpu().numpy()[:, np.where(self.VCF_filtered[0].to_numpy() == SNP_name)[0][0]]\n",
    "    \n",
    "    AF_density = np.round(AF_SNP * 100).astype(int)\n",
    "    \n",
    "    counter = collections.Counter(AF_density)\n",
    "    numbers_AF = list(counter.keys())\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1, dpi = dpi)\n",
    "    fig.set_size_inches(6, 5)\n",
    "\n",
    "    axs.set_title(SNP_name)\n",
    "\n",
    "    for j in numbers_AF:\n",
    "\n",
    "        axs.scatter(self.embedding_2d[AF_density == j, 0], self.embedding_2d[AF_density == j, 1], s = 5, color = color_AF[j])\n",
    "\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "    axs.set_xlabel(\"UMAP1\")\n",
    "    axs.set_ylabel(\"UMAP2\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f71d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNP_VAE:\n",
    "    \n",
    "    def __init__(self, path = None, mitoSNP_mask = [3107, 310], AD = None, DP = None, VCF = None, variant_name = None, SNPread = \"normalized\", missing_value = 0.5, cell_weight = \"unnormalized\"):\n",
    "        \n",
    "        self.SNPread = SNPread\n",
    "        self.missing_value = missing_value\n",
    "        self.cell_weight = cell_weight\n",
    "        load_data(self, path, mitoSNP_mask, AD, DP, VCF, variant_name)\n",
    "        \n",
    "    def filtering(self):\n",
    "        \n",
    "        filter_data(self)\n",
    "        \n",
    "    def training(self, num_epoch = 2000, stepsize = 0.0001, z_dim = None, beta = 0, num_batch = 5):\n",
    "        \n",
    "        train_VAE(self, num_epoch, stepsize, z_dim, beta, num_batch)\n",
    "        \n",
    "    def retrain_umap(self):\n",
    "        \n",
    "        umap_retrain(self)\n",
    "        \n",
    "    def clustering(self, algorithm = \"leiden_umap3d\", max_cluster = 15, resolution = 1):\n",
    "\n",
    "        latent_clustering(self, algorithm, max_cluster, resolution)\n",
    "        \n",
    "    def phylogeny(self, cluster_no = 2, pair_no = 100, SNP_no = 50, bad_color = \"blue\", cmap_heatmap = mpl.colormaps['rocket']):\n",
    "        \n",
    "        tree(self, cluster_no, pair_no, SNP_no, bad_color, cmap_heatmap)\n",
    "        \n",
    "    def filtering_summary(self, dpi = mpl.rcParams['figure.dpi']):\n",
    "        \n",
    "        summary_filtering(self, dpi)\n",
    "        \n",
    "    def training_summary(self, dpi = mpl.rcParams['figure.dpi']):\n",
    "        \n",
    "        summary_training(self, dpi)\n",
    "        \n",
    "    def clustering_summary(self, dpi = mpl.rcParams['figure.dpi']):\n",
    "        \n",
    "        summary_clustering(self, dpi)\n",
    "        \n",
    "    def phylogeny_summary(self, SNP_no = None, dpi = mpl.rcParams['figure.dpi'], bad_color = \"blue\", fontsize_c = None, fontsize_x = None, fontsize_y = None, cmap_heatmap = mpl.colormaps['rocket']):\n",
    "        \n",
    "        summary_phylogeny(self, SNP_no, dpi, bad_color, fontsize_c, fontsize_x, fontsize_y, cmap_heatmap)\n",
    "        \n",
    "    def AF_scatter(self, SNP_name, dpi = mpl.rcParams['figure.dpi']):\n",
    "        \n",
    "        scatter_AF(self, SNP_name, dpi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
